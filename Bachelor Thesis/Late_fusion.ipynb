{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b6f85e-a826-4da0-994f-3495d0e356a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from random import shuffle, sample\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler, ConcatDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "from torch.utils.data import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183ca3db-8474-48d4-930a-1f0bc5fdc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"action_recognition_dataset\"\n",
    "tools = [\"spatula\",\"ruler\",\"hook\",\"sshot\"]\n",
    "actions = [\"left_to_right\",\"pull\",\"push\",\"right_to_left\"]\n",
    "objects = ['woodenCube', 'tomatoCan', 'boxMilk', 'containerNuts', 'cornCob', 'yellowFruitToy', 'bottleNailPolisher', 'boxRealSense', 'clampOrange', 'greenRectangleToy', 'ketchupToy', 'peartoy', 'yogurtYellowbottle', 'cowToy', 'tennisBallYellowGreen', 'blackCoinBag', 'lemonSodaCan', 'peperoneGreenToy', 'boxEgg', 'pumpkinToy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c84920-8376-48ad-a7f8-8dd75daa1f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b0b320-a3ae-4dc2-a92f-16cc6c3ed867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImageC(path):\n",
    "    image = None\n",
    "    transform = transforms.Compose([transforms.Resize((64,64)),\n",
    "                                     transforms.ToTensor()\n",
    "                                    ])\n",
    "    with Image.open(path) as im:\n",
    "        image=im.convert(\"RGB\")\n",
    "        image= transform(image)\n",
    "        mean= image.mean([1,2])\n",
    "        std = image.std([1,2])\n",
    "        image = transforms.Normalize(mean,std)(image)\n",
    "    return image\n",
    "\n",
    "def openImageD(path):\n",
    "    image = None\n",
    "    transform = transforms.Compose([transforms.Resize((64,64)),\n",
    "                                     transforms.ToTensor()\n",
    "                                    ])\n",
    "    with Image.open(path) as im:\n",
    "        image=im.convert(\"RGB\")\n",
    "        image= transform(image)\n",
    "        mean= image.mean([1,2])\n",
    "        std = image.std([1,2])\n",
    "        if std[0]==0:\n",
    "            std[0]=1\n",
    "        image = transforms.Normalize(mean,std)(image)\n",
    "    return image\n",
    "\n",
    "def setDataframe(path, tools, actions):\n",
    "    dataset = pd.DataFrame()\n",
    "    directories = os.listdir(path)\n",
    "    \n",
    "    \n",
    "    for iFolder in range(len(directories)):\n",
    "        objs = directories[iFolder]\n",
    "        obj = objs.split(\"_\")[1]\n",
    "        objects.append(obj)\n",
    "        for act in actions:\n",
    "            for tool in tools:\n",
    "                for i in range(10):\n",
    "                    path = os.path.join(dataPath,objs,tool,act)\n",
    "                    initColor = openImageC(os.path.join(path,\"color\",f\"init_color_{i}.png\"))\n",
    "                    initDepth = openImageD(os.path.join(path,\"depthcolormap\",f\"init_depthcolormap_{i}.png\"))\n",
    "                    effectColor = openImageC(os.path.join(path,\"color\",f\"effect_color_{i}.png\"))\n",
    "                    effectDepth = openImageD(os.path.join(path,\"depthcolormap\",f\"effect_depthcolormap_{i}.png\"))\n",
    "                    \n",
    "                    frames = [obj,tool,act,initColor,effectColor,initDepth,effectDepth]\n",
    "                    dataset=pd.concat([dataset,pd.Series(frames).to_frame().T],ignore_index=True)\n",
    "    \n",
    "    dataset = dataset.rename(columns ={0: \"Object\" ,1: \"Tool\",2:\"Action\", 3:\"Color Initial\",4:\"Color Effect\",5:\"Depthcolor Initial\",6:\"Depthcolor Effect\"})\n",
    "    return dataset\n",
    "        \n",
    "def label_encode(entries, labels):\n",
    "    dictL = dict()\n",
    "    res = list()\n",
    "    for i, label in enumerate(labels):\n",
    "        dictL[label] = i\n",
    "    \n",
    "    for entrie in entries:\n",
    "        res.append(dictL[entrie])\n",
    "    \n",
    "    return pd.Series(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7ebcf8-edc8-47e0-abf6-8b89ed75c4a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'action_recognition_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43msetDataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m, in \u001b[0;36msetDataframe\u001b[1;34m(path, tools, actions)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetDataframe\u001b[39m(path, tools, actions):\n\u001b[0;32m     30\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m---> 31\u001b[0m     directories \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iFolder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(directories)):\n\u001b[0;32m     35\u001b[0m         objs \u001b[38;5;241m=\u001b[39m directories[iFolder]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'action_recognition_dataset'"
     ]
    }
   ],
   "source": [
    "dataset = setDataframe(dataPath,tools,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f6687-6539-4d33-9677-c7035dc5c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[\"ActionL\"] = label_encode(dataset[\"Action\"],actions)\n",
    "dataset[\"ToolL\"]   = label_encode(dataset[\"Tool\"],tools)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a9b11-3832-414e-8ff1-183ca448dabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4829b55-1aca-4cda-9086-f3483210b216",
   "metadata": {},
   "source": [
    " # Late Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb105e4f-3858-47bb-a3a3-911c79b1107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(numOutputC, n_layerC, numOutputH, n_layerH):\n",
    "    model=nn.Sequential()\n",
    "    model.add_module(\"Conv0\",nn.Conv2d(3, numOutputC[0], kernel_size = 3, padding = 1))\n",
    "    model.add_module(\"Relu0\",nn.ReLU())\n",
    "    model.add_module(\"Norm0\",nn.BatchNorm2d(numOutputC[0]))\n",
    "    model.add_module(\"MaxPool0\",nn.MaxPool2d(2,2))\n",
    "    \n",
    "    i=0\n",
    "    while i < n_layerC-1:\n",
    "        model.add_module(f\"Conv{i+1}\",nn.Conv2d(numOutputC[i], numOutputC[i+1], kernel_size = 3, padding = 1))\n",
    "        model.add_module(f\"Relu{i+1}\",nn.ReLU())\n",
    "        model.add_module(f\"Norm{i+1}\",nn.BatchNorm2d(numOutputC[i+1]))\n",
    "        model.add_module(f\"MaxPool{i+1}\",nn.MaxPool2d(2,2))\n",
    "        i+=1\n",
    "        \n",
    "    model.add_module(\"Flatten\", nn.Flatten())\n",
    "\n",
    "#(2**(18-n_layerC)\n",
    "\n",
    "    model.add_module(\"Drop\",nn.Dropout(0.4))\n",
    "    model.add_module(\"Linear\",nn.Linear(2**(17-n_layerC),numOutputH[0]))\n",
    "    model.add_module(\"ReluH0\",nn.ReLU())\n",
    "    model.add_module(\"NormH0\",nn.BatchNorm1d(numOutputH[0]))\n",
    "    i=0\n",
    "    while i< n_layerH-1:\n",
    "        \n",
    "        model.add_module(f\"Drop{i+1}\",nn.Dropout(0.4))\n",
    "        model.add_module(f\"Linear{i+1}\",nn.Linear(numOutputH[i], numOutputH[i+1]))\n",
    "        model.add_module(f\"ReluH{i+1}\",nn.ReLU())\n",
    "        model.add_module(f\"NormH{i+1}\",nn.BatchNorm1d(numOutputH[i+1]))\n",
    "        i+=1\n",
    "    return model\n",
    "\n",
    "def buildD(numOutputC, n_layerC, numOutputH, n_layerH):\n",
    "    model=nn.Sequential()\n",
    "    model.add_module(\"Conv0\",nn.Conv2d(3, numOutputC[0], kernel_size = 3, padding = 1))\n",
    "    model.add_module(\"Relu0\",nn.LeakyReLU(0.3))\n",
    "    model.add_module(\"Norm0\",nn.BatchNorm2d(numOutputC[0]))\n",
    "    model.add_module(\"MaxPool0\",nn.MaxPool2d(2,2))\n",
    "    \n",
    "    i=0\n",
    "    while i < n_layerC-1:\n",
    "        model.add_module(f\"Conv{i+1}\",nn.Conv2d(numOutputC[i], numOutputC[i+1], kernel_size = 3, padding = 1))\n",
    "        model.add_module(f\"Relu{i+1}\",nn.LeakyReLU(0.3))\n",
    "        model.add_module(f\"Norm{i+1}\",nn.BatchNorm2d(numOutputC[i+1]))\n",
    "        model.add_module(f\"MaxPool{i+1}\",nn.MaxPool2d(2,2))\n",
    "        i+=1\n",
    "        \n",
    "    model.add_module(\"Flatten\", nn.Flatten())\n",
    "\n",
    "\n",
    "\n",
    "    model.add_module(\"Drop\",nn.Dropout(0.4))\n",
    "    model.add_module(\"Linear\",nn.Linear(2**(17-n_layerC),numOutputH[0]))\n",
    "    model.add_module(\"ReluH0\",nn.LeakyReLU(0.3))\n",
    "    model.add_module(\"NormH0\",nn.BatchNorm1d(numOutputH[0]))\n",
    "    i=0\n",
    "    while i< n_layerH-1:\n",
    "        \n",
    "        model.add_module(f\"Drop{i+1}\",nn.Dropout(0.4))\n",
    "        model.add_module(f\"Linear{i+1}\",nn.Linear(numOutputH[i], numOutputH[i+1]))\n",
    "        model.add_module(f\"ReluH{i+1}\",nn.LeakyReLU(0.3))\n",
    "        model.add_module(f\"NormH{i+1}\",nn.BatchNorm1d(numOutputH[i+1]))\n",
    "        i+=1\n",
    "    return model\n",
    "\n",
    "\n",
    "class ImageLateFClassifier(nn.Module):\n",
    "    def __init__(self, numOutputC, n_layerC, numOutputH, n_layerH, depth):\n",
    "        super().__init__()\n",
    "        \n",
    "        model = None\n",
    "        if(depth):\n",
    "            model = buildD(numOutputC, n_layerC, numOutputH, n_layerH)\n",
    "        else:\n",
    "            model = build(numOutputC, n_layerC, numOutputH, n_layerH)\n",
    "        self.network = model\n",
    "        self.fc1= nn.Linear(numOutputH[-1],4)\n",
    "        self.fc2= nn.Linear(numOutputH[-1],4)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = self.network(xb)\n",
    "        label2 = self.fc1(xb)\n",
    "        label1 = self.fc2(xb)\n",
    "\n",
    "        return {'Tool': label1, 'Action': label2}\n",
    "\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch,crit):\n",
    "        images, l1,l2, = batch\n",
    "        images, l1,l2= images.to(device), l1.to(device), l2.to(device)\n",
    "        \n",
    "        out = self(images)     \n",
    "        \n",
    "        loss1 = crit(out[\"Action\"], l1)\n",
    "        loss2 = crit(out[\"Tool\"], l2)\n",
    "        return loss1, loss2\n",
    "    \n",
    "    def validation_step(self, batch,crit):\n",
    "        images, l1,l2 = batch\n",
    "        images, l1,l2= images.to(device), l1.to(device), l2.to(device)\n",
    "        \n",
    "        out = self(images)     \n",
    "        \n",
    "        loss1 = crit(out[\"Action\"], l1)\n",
    "        loss2 = crit(out[\"Tool\"], l2) \n",
    "        loss = loss1+loss2\n",
    "        \n",
    "\n",
    "        acc1 = accuracy(out[\"Action\"], l1)\n",
    "        acc2 = accuracy(out[\"Tool\"], l2) \n",
    "        acc = (acc1+acc2)/2\n",
    "        return {'val_loss': loss.detach(), \"val_acc\": acc, 'val_acc_Action': acc1, 'val_acc_Tool': acc2}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      \n",
    "        batch_accs1 = [x['val_acc_Tool'] for x in outputs]\n",
    "        epoch_acc1 = torch.stack(batch_accs1).mean()\n",
    "        batch_accs2 = [x['val_acc_Action'] for x in outputs]\n",
    "        epoch_acc2 = torch.stack(batch_accs2).mean()\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item(), 'val_acc_Tool': epoch_acc1.item(), 'val_acc_Action': epoch_acc2.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}, val_acc_Tool: {:.4f}, val_acc_Action: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'],result['val_acc'],result['val_acc_Tool'],result['val_acc_Action']))\n",
    "            \n",
    "            \n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "\n",
    "def evaluate(model, val_loader,crit):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch,crit) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD, crit =nn.CrossEntropyLoss()):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    count=0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss1, loss2 = model.training_step(batch,crit)\n",
    "            loss = loss1+loss2\n",
    "            \n",
    "            train_losses.append(loss)\n",
    "                     \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        result = evaluate(model, val_loader,crit)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        if result[\"train_loss\"] - result[\"val_loss\"] < 0:\n",
    "            if count > 2:\n",
    "                break\n",
    "            else:\n",
    "                count+=1\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e4996-0e6c-4f92-9e23-beb276df4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinTensor(*args):\n",
    "    l = list()\n",
    "    for i in range(len(args[0])):\n",
    "        newT = torch.cat((args[0][i],args[1][i]),1)\n",
    "        l.append(newT)\n",
    "    s = pd.Series(l)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d121b61-79c6-4d06-a8e6-ddfdc750c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    " \n",
    "    def __init__(self,df):\n",
    "        df=df\n",
    " \n",
    "        x=df.iloc[:,0].values\n",
    "        y=df.iloc[:,1].values\n",
    "        y2=df.iloc[:,2].values\n",
    "\n",
    "        \n",
    "        \n",
    " \n",
    "        self.x_train=x\n",
    "        self.y_train=y\n",
    "        self.y2_train=y2\n",
    "\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx],self.y_train[idx],self.y2_train[idx]\n",
    "    \n",
    "    def getX(self):\n",
    "        return self.x_train\n",
    "    \n",
    "    def getYA(self):\n",
    "        return self.y_train\n",
    "    \n",
    "    def getYT(self):\n",
    "        return self.y2_train\n",
    "\n",
    "\n",
    "    \n",
    "def plot_accuracies_losses(history,title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    ax1.plot(accuracies, '-x')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_title('Accuracy vs. No. of epochs')\n",
    "\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    ax2.plot(train_losses, '-bx')\n",
    "    ax2.plot(val_losses, '-rx')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.legend(['Training', 'Validation'])\n",
    "    ax2.set_title('Loss vs. No. of epochs')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039935f0-bd77-44c3-b3ab-9423bef823b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lateD = pd.DataFrame()\n",
    "lateD[[\"ActionL\",\"ToolL\",\"Color Initial\",\"Color Effect\",\"Depthcolor Initial\",\"Depthcolor Effect\"]] = dataset[[\"ActionL\",\"ToolL\",\"Color Initial\",\"Color Effect\",\"Depthcolor Initial\",\"Depthcolor Effect\"]]\n",
    "lateD[\"fusedC\"] = joinTensor(dataset[\"Color Initial\"],dataset[\"Color Effect\"])\n",
    "lateD[\"fusedD\"] = joinTensor(dataset[\"Depthcolor Initial\"],dataset[\"Depthcolor Effect\"])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_data, val_data = train_test_split(lateD[[\"fusedC\",\"fusedD\",\"ActionL\",\"ToolL\"]], test_size=0.3)\n",
    "val_data, test_data = train_test_split(val_data,test_size=0.5)\n",
    "\n",
    "\n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "train_dataC = MyDataset(train_data[[\"fusedC\",\"ActionL\",\"ToolL\"]])\n",
    "val_dataC = MyDataset(val_data[[\"fusedC\",\"ActionL\",\"ToolL\"]])\n",
    "test_dataC = MyDataset(test_data[[\"fusedC\",\"ActionL\",\"ToolL\"]])\n",
    "\n",
    "train_dataD = MyDataset(train_data[[\"fusedD\",\"ActionL\",\"ToolL\"]])\n",
    "val_dataD = MyDataset(val_data[[\"fusedD\",\"ActionL\",\"ToolL\"]])\n",
    "test_dataD = MyDataset(test_data[[\"fusedD\",\"ActionL\",\"ToolL\"]])\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_dlC = DataLoader(train_dataC, batch_size)\n",
    "val_dlC = DataLoader(val_dataC, batch_size)\n",
    "test_dlC = DataLoader(test_dataC, 480)\n",
    "\n",
    "train_dlD = DataLoader(train_dataD, batch_size)\n",
    "val_dlD = DataLoader(val_dataD, batch_size)\n",
    "test_dlD = DataLoader(test_dataD, 480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aebb6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d978767",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b628529a",
   "metadata": {},
   "source": [
    "D 0.7270 leaky C 0.3\n",
    "R 0.5390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3992eafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aea465d5",
   "metadata": {},
   "source": [
    "bestC = []\n",
    "bestD = []\n",
    "num_epochs = [100]\n",
    "opt_func = torch.optim.Adam\n",
    "lrs = [0.001,0.0001]\n",
    "numOutputH = [1024,512,256,128,64,32]\n",
    "numOutputH1 = [1024,256,64,32,16]\n",
    "numOutputH2 = [512,256,64,16]\n",
    "\n",
    "numOutputH = numOutputH1\n",
    "numOutputC = [32,64,128,256,512]\n",
    "\n",
    "#Hyperparameter and architecture testing\n",
    "\n",
    "for epoch in num_epochs:\n",
    "    for lr in lrs:\n",
    "        for n_layerC in range(2,len(numOutputC)):\n",
    "            for n_layerH in range(2,len(numOutputH)):\n",
    "                inH = numOutputH[:]\n",
    "                inH.reverse()\n",
    "                inH = inH[:n_layerH]\n",
    "                inH.reverse()\n",
    "                \n",
    "                \n",
    "                modelC = ImageLateFClassifier(numOutputC[:n_layerC], n_layerC, inH, n_layerH)\n",
    "                modelD = ImageLateFClassifier(numOutputC[:n_layerC], n_layerC, inH, n_layerH)\n",
    "                \n",
    "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "                print(device)\n",
    "                modelC = modelC.to(device)\n",
    "                \n",
    "                historyC = fit(epoch, lr, modelC, train_dlC, val_dlC, opt_func)\n",
    "                plot_accuracies_losses(historyC,f\"RGB model Number of epochs {epoch}, Learning rate {lr}, Hidden layers {n_layerH}, Number Convolution {n_layerC}, OutputC {numOutputC[:n_layerC]}, OutputH {inH}\")\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                \n",
    "                modelD = modelD.to(device)\n",
    "                historyD = fit(2*epoch, lr, modelD, train_dlD, val_dlD, opt_func)\n",
    "                plot_accuracies_losses(historyD,f\"Depth model Number of epochs {epoch*2}, Learning rate {lr}, Hidden layers {n_layerH}, Number Convolution {n_layerC}, OutputC {numOutputC[:n_layerC]}, OutputH {inH}\")\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                mV = [x['val_acc'] for x in historyC][-1]\n",
    "                mTL = [x['train_loss'] for x in historyC][-1]\n",
    "                mVL = [x['val_loss'] for x in historyC][-1]\n",
    "                mVT = [x['val_acc_Tool'] for x in historyC][-1]\n",
    "                mVA = [x['val_acc_Action'] for x in historyC][-1]\n",
    "                \n",
    "                bestC.append((mV,mTL,mVL,mVT,mVA,\"nH\"+str(n_layerH),\"nC\"+str(n_layerC)))\n",
    "                \n",
    "                mV = [x['val_acc'] for x in historyD][-1]\n",
    "                mTL = [x['train_loss'] for x in historyD][-1]\n",
    "                mVL = [x['val_loss'] for x in historyD][-1]\n",
    "                mVT = [x['val_acc_Tool'] for x in historyD][-1]\n",
    "                mVA = [x['val_acc_Action'] for x in historyD][-1]\n",
    "                \n",
    "                bestD.append((mV,mTL,mVL,mVT,mVA,\"nH\"+str(n_layerH),\"nC\"+str(n_layerC)))\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfcba3f",
   "metadata": {},
   "source": [
    "bestC.sort(key=lambda x: x[4], reverse=True)\n",
    "print(bestC[0])\n",
    "\n",
    "bestD.sort(key=lambda x: x[4],reverse=True)\n",
    "print(bestD[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20657c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epoch = 100\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.0001\n",
    "numOutputH = [64,32,16]\n",
    "numOutputC = [32,64]\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "modelsC = []\n",
    "k=10\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={}\n",
    "\n",
    "history = {'train_loss': [], 'test_loss': [],'test_acc_Tool':[],'test_acc_Action':[],'test_acc':[]}\n",
    "dataset = ConcatDataset([train_dataC, val_dataC])\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    inH = numOutputH[:]\n",
    "    inH.reverse()\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    model = ImageLateFClassifier(numOutputC, len(numOutputC), inH, len(inH), False)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam\n",
    "    h = fit(epoch, lr, model, train_loader, test_loader, optimizer)\n",
    "    \n",
    "    modelsC.append(model)\n",
    "    dif = [(x['train_loss']-x['val_loss'],x['val_acc'],x['train_loss'],x['val_loss'],x['val_acc_Tool'],x['val_acc_Action']) for x in h if x['train_loss']-x['val_loss'] > 0]\n",
    "    \n",
    "    history['train_loss'].append(dif[-1][2])\n",
    "    history['test_loss'].append(dif[-1][3])\n",
    "    history['test_acc_Tool'].append(dif[-1][4])\n",
    "    history['test_acc_Action'].append(dif[-1][5])\n",
    "    history['test_acc'].append(dif[-1][1])  \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed18aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_loss = np.mean(history['train_loss'])\n",
    "avg_test_loss = np.mean(history['test_loss'])\n",
    "avg_test_acc = np.mean(history['test_acc'])\n",
    "avg_test_acc_Tool = np.mean(history['test_acc_Tool'])\n",
    "avg_test_acc_Action = np.mean(history['test_acc_Action'])\n",
    "\n",
    "historyC = history\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f}  \\t Average Test Acc: {:.3f} \\t Average Test Acc Tool: {:.3f} \\t Average Test Acc Action: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_test_acc,avg_test_acc_Tool,avg_test_acc_Action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb773fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 400\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.0001\n",
    "numOutputH = [64,32,16]\n",
    "numOutputC = [32,64]\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "modelsD = []\n",
    "history = {'train_loss': [], 'test_loss': [],'test_acc_Tool':[],'test_acc_Action':[],'test_acc':[]}\n",
    "dataset = ConcatDataset([train_dataD, val_dataD])\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    inH = numOutputH[:]\n",
    "    inH.reverse()\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    model = ImageLateFClassifier(numOutputC, len(numOutputC), inH, len(inH), True)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam\n",
    "    h = fit(epoch, lr, model, train_loader, test_loader, optimizer)\n",
    "    \n",
    "    modelsD.append(model)\n",
    "    dif = [(x['train_loss']-x['val_loss'],x['val_acc'],x['train_loss'],x['val_loss'],x['val_acc_Tool'],x['val_acc_Action']) for x in h]\n",
    "    \n",
    "    history['train_loss'].append(dif[-1][2])\n",
    "    history['test_loss'].append(dif[-1][3])\n",
    "    history['test_acc_Tool'].append(dif[-1][4])\n",
    "    history['test_acc_Action'].append(dif[-1][5])\n",
    "    history['test_acc'].append(dif[-1][1])  \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382c743",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_loss = np.mean(history['train_loss'])\n",
    "avg_test_loss = np.mean(history['test_loss'])\n",
    "avg_test_acc = np.mean(history['test_acc'])\n",
    "avg_test_acc_Tool = np.mean(history['test_acc_Tool'])\n",
    "avg_test_acc_Action = np.mean(history['test_acc_Action'])\n",
    "\n",
    "historyD = history\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f}  \\t Average Test Acc: {:.3f} \\t Average Test Acc Tool: {:.3f} \\t Average Test Acc Action: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_test_acc,avg_test_acc_Tool,avg_test_acc_Action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestMC = max(historyC[\"test_acc_Tool\"])\n",
    "bestMD = max(historyD[\"test_acc_Tool\"])\n",
    "modelD = modelsD[historyD[\"test_acc_Tool\"].index(bestMD)]\n",
    "modelC = modelsC[historyC[\"test_acc_Tool\"].index(bestMC)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8478b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    model.eval()\n",
    "    \n",
    "    for images, l1, l2 in loader:\n",
    "        images, l1,l2 = images.to(device), l1.to(device), l2.to(device)\n",
    "        \n",
    "        preds = model(images)\n",
    "        predsA = preds[\"Action\"].to(\"cpu\")\n",
    "        predsT = preds[\"Tool\"].to(\"cpu\")\n",
    "        all_predsA = torch.cat((all_preds, predsA), dim=0)\n",
    "        all_predsT = torch.cat((all_preds, predsT), dim=0)\n",
    "    return all_predsA, all_predsT\n",
    "\n",
    "\n",
    "def get_all_combined_preds(modelC,modelD,loaderC,loaderD):\n",
    "    predsAC, predsTC = get_all_preds(modelC, loaderC)\n",
    "    predsAD, predsTD = get_all_preds(modelD, loaderD)\n",
    "    \n",
    "    \n",
    "    average_resA = (predsAC+predsAD)/2\n",
    "    average_resT = (predsTC+predsTD)/2\n",
    "    \n",
    "    \n",
    "    return average_resA, average_resT\n",
    "\n",
    "with torch.no_grad(): \n",
    "    predsAC, predsTC = get_all_preds(modelC, test_dlC)\n",
    "    predsAD, predsTD = get_all_preds(modelD, test_dlD)\n",
    "    \n",
    "    predsAVD, predsTVD = get_all_combined_preds(modelC,modelD,test_dlC,test_dlD)\n",
    "\n",
    "\n",
    "\n",
    "cmAC = confusion_matrix(test_dataC.getYA(), predsAC.argmax(dim=-1))\n",
    "cmTC = confusion_matrix(test_dataC.getYT(), predsTC.argmax(dim=-1))\n",
    "cmAD = confusion_matrix(test_dataD.getYA(), predsAD.argmax(dim=-1))\n",
    "cmTD = confusion_matrix(test_dataD.getYT(), predsTD.argmax(dim=-1))\n",
    "cmAVD = confusion_matrix(test_dataC.getYA(), predsAVD.argmax(dim=-1))\n",
    "cmTVD = confusion_matrix(test_dataC.getYT(), predsTVD.argmax(dim=-1))\n",
    "\n",
    "print(\"RGB results\")\n",
    "report = classification_report(test_dataC.getYA(),predsAC.argmax(dim=-1), target_names=['push', 'pull', 'left to right', \"right to left\"], zero_division= 0)\n",
    "print('Classification Report A: ', report)\n",
    "\n",
    "report = classification_report(test_dataC.getYT(),predsTC.argmax(dim=-1), target_names=['sshot', 'spatula', 'hook', \"ruler\"], zero_division= 0)\n",
    "print('Classification Report T: ', report)\n",
    "    \n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cmAC, display_labels=['push', 'pull', 'left to right', \"right to left\"])\n",
    "display.plot()\n",
    "plt.show()\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cmTC, display_labels=['sshot', 'spatula', 'hook', \"ruler\"])\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Depth results\")\n",
    "report = classification_report(test_dataD.getYA(),predsAD.argmax(dim=-1), target_names=['push', 'pull', 'left to right', \"right to left\"], zero_division= 0)\n",
    "print('Classification Report A: ', report)\n",
    "\n",
    "report = classification_report(test_dataD.getYT(),predsTD.argmax(dim=-1), target_names=['sshot', 'spatula', 'hook', \"ruler\"], zero_division= 0)\n",
    "print('Classification Report T: ', report)\n",
    "    \n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cmAD, display_labels=['push', 'pull', 'left to right', \"right to left\"])\n",
    "display.plot()\n",
    "plt.show()\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cmTD, display_labels=['sshot', 'spatula', 'hook', \"ruler\"])\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "print(\"Average results\")\n",
    "report = classification_report(test_dataC.getYA(),predsAVD.argmax(dim=-1), target_names=['push', 'pull', 'left to right', \"right to left\"], zero_division= 0)\n",
    "print('Classification Report A: ', report)\n",
    "\n",
    "report = classification_report(test_dataC.getYT(),predsTVD.argmax(dim=-1), target_names=['sshot', 'spatula', 'hook', \"ruler\"], zero_division= 0)\n",
    "print('Classification Report T: ', report)\n",
    "    \n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cmAVD, display_labels=['push', 'pull', 'left to right', \"right to left\"])\n",
    "display.plot()\n",
    "plt.show()\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cmTVD, display_labels=['sshot', 'spatula', 'hook', \"ruler\"])\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a8237",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
